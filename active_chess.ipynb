{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of the United States is Washington, D.C. This city serves as the center of the federal government, housing major institutions like the White House, the Capitol, and the Supreme Court.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import asyncio\n",
    "from typing import Optional, Type, Any, Dict, Union, Tuple, List\n",
    "from pydantic import BaseModel\n",
    "import logging\n",
    "\n",
    "load_dotenv()  # This loads the .env file into the environment\n",
    "\n",
    "import openai\n",
    "\n",
    "client = openai.AsyncOpenAI()\n",
    "\n",
    "async def call_openai(\n",
    "    messages,\n",
    "    model_name = \"o3-mini\",\n",
    "    output_type: Optional[Type[BaseModel]] = None,\n",
    "    max_tokens: int = 1500,\n",
    "    reasoning_effort = \"medium\",\n",
    "    max_retries=3,\n",
    "    tools: Optional[Dict[str, Any]] = None,\n",
    ") -> Union[str, BaseModel]:\n",
    "    \"\"\"\n",
    "    Calls the LLM using OpenAI's chat completion or HF, returning either raw text\n",
    "    or a Pydantic-validated object.\n",
    "    \"\"\"\n",
    "\n",
    "    last_exception = None\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            if output_type is None:\n",
    "                response = await client.chat.completions.create(\n",
    "                    messages=messages,\n",
    "                    model=model_name,\n",
    "                    max_completion_tokens=max_tokens,\n",
    "                    tools=tools\n",
    "                )\n",
    "                if tools:\n",
    "                    print(response)\n",
    "                    result = response.choices[0].message\n",
    "                else:\n",
    "                    result = response.choices[0].message.content\n",
    "                # logging.info(\"\\nRESPONSE:\", result)\n",
    "                # logging.info(\"=\" * 80)\n",
    "                return result\n",
    "            else:\n",
    "                response = await client.beta.chat.completions.parse(\n",
    "                    messages=messages,\n",
    "                    model=model_name,\n",
    "                    max_completion_tokens=max_tokens,\n",
    "                    response_format=output_type,\n",
    "                )\n",
    "                parsed_obj = response.choices[0].message.parsed\n",
    "                result = output_type.model_validate(parsed_obj)\n",
    "                # logging.info(\"\\nRESPONSE:\", result)\n",
    "                # logging.info(\"=\" * 80)\n",
    "                return result\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.info(\n",
    "                f\"[DEBUG] Attempt {attempt+1}/{max_retries} failed with exception: {e}\"\n",
    "            )\n",
    "            logging.info(\"[DEBUG] User messages (verbatim):\")\n",
    "            for idx, msg in enumerate(messages):\n",
    "                logging.info(f\"  Message {idx+1} - role='{msg['role']}':\")\n",
    "                logging.info(msg[\"content\"])\n",
    "            last_exception = e\n",
    "            await asyncio.sleep(1.0 * (attempt + 1))\n",
    "\n",
    "    raise last_exception\n",
    "\n",
    "\n",
    "await call_openai(messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of the United States?\"},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propose_new_tool = {\n",
    "    \"name\": \"propose_new_tool\",\n",
    "    \"description\": \"Propose the function specs for one or two new python functions you can call anytime as new tool calls later on. Brainstorm some functions that do specific algorithmic computations about the board that helps your decision, and write detailed specs of those.\",\n",
    "    \"input_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"tool_name_1\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Name of the tool you will use\"\n",
    "            },\n",
    "            \"tool_name_2\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Name of the tool you will use\"\n",
    "            },\n",
    "            \"function_spec_1\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"A detailed description of the function you want to propose, as well as the signature of its outputs. The function should only receive an input which is a 2D array representing the current visible board state, where in the array X represents a hit, O represents a miss, and ~ represents unknown cells.\"  \n",
    "            },\n",
    "            \"function_spec_2\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"A detailed description of the function you want to propose, as well as the signature of its outputs. The function should only receive an input which is a 2D array representing the current visible board state, where in the array X represents a hit, O represents a miss, and ~ represents unknown cells.\"  \n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"tool_name_1\", \"function_spec_1\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Move(BaseModel):\n",
    "    action: str\n",
    "    desc: str\n",
    "    score: Optional[float] = None\n",
    "\n",
    "\n",
    "class MoveChoices(BaseModel):\n",
    "    choices: List[Move]\n",
    "\n",
    "\n",
    "class ChessGame:\n",
    "    def __init__(self, env):\n",
    "        self.env = env"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
